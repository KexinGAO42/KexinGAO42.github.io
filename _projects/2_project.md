---
layout: page
title: Complexity Study of Morphological Paradigms
description: An investigation into the complexity and learnability of morphological paradigms.
img:
importance: 2
category: research
---

**Keyword**: morphological complexity, learning, neural networks, typology

## About

This work was conducted at the [Center for Language Evolution](https://cle.ppls.ed.ac.uk/) at [The University of Edinburgh](https://www.ed.ac.uk/), along with [Dr. Tamar Johnson](https://www.illc.uva.nl/People/person/5427/Dr-Tamar-Johnson), [Prof. Kenny Smith](https://lel.ed.ac.uk/~kenny/), [Prof. Hugh Rabagliati](https://www.ed.ac.uk/profile/hugh-rabagliati) and [Prof. Jennifer Culbertson](https://www.ed.ac.uk/profile/jennifer-culbertson).

I designed the paradigms and conducted all experiments and the statistical analysis in this work.

The original version of this work (my Master Thesis) was awarded Highly Commended Dissertation of the school year.

## Abstract

Research on cross-linguistic differences in morphological paradigms reveals a wide range of variation on many dimensions, including the number of categories expressed, the number of unique forms, and the number of inflectional classes. However, in an influential paper, Ackerman and Malouf (2013) argue that there is one dimension on which languages do not differ widely: in predictive structure. Predictive structure in a paradigm describes the extent to which forms predict each other, called i-complexity. Ackerman and Malouf (2013) show that although languages differ according to measure of surface paradigm complexity, called e-complexity, they tend to have low i-complexity. They conclude that morphological paradigms have evolved under a pressure for low i-complexity. Here, we evaluate the hypothesis that language learners are more sensitive to i-complexity than e-complexity by testing how well paradigms which differ on only these dimensions are learned. This could result in the typological findings Ackerman and Malouf (2013) report if even paradigms with very high e-complexity are relatively easy to learn, so long as they have low i-complexity. First, we summarize a recent work by Johnson et al. (2020) suggesting that both neural networks and human learners may actually be more sensitive to e-complexity than i-complexity. Then we build on this work, reporting a series of experiments which confirm that, indeed, across a range of paradigms that vary in either e- or i-complexity, neural networks (LSTMs) are sensitive to both, but show a larger effect of e-complexity (and other measures associated with size and diversity of forms). In human learners, we fail to find any effect of i-complexity on learning at all. Finally, we analyse a large number of randomly generated paradigms and show that e- and i-complexity are negatively correlated: paradigms with high e-complexity necessarily show low i-complexity. We discuss what these findings might mean for Ackerman and Malouf’s hypothesis, as well as the role of ease of learning versus generalization to novel forms in the evolution of paradigms.

## Paper

[Link](https://jlm.ipipan.waw.pl/index.php/JLM/article/view/259)

```
@article{Johnson_Gao_Smith_Rabagliati_Culbertson_2021, 
    author={Johnson, Tamar and Gao, Kexin and Smith, Kenny and Rabagliati, Hugh and Culbertson, Jennifer}, 
    title={Investigating the effects of i-complexity and e-complexity on the learnability of morphological systems}, 
    url={https://jlm.ipipan.waw.pl/index.php/JLM/article/view/259}, 
    volume={9}, 
    DOI={10.15398/jlm.v9i1.259}, 
    number={1}, 
    journal={Journal of Language Modelling}, 
    year={2021}, month={Oct.}, pages={97–150}}
```

